services:
  nginx:
    image: nginx:1.29-alpine
    container_name: rinha-nginx
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api1
      # - api2
    ports:
      - "9999:9999"
    networks:
      - backend
      - payment-processor
    deploy:
      resources:
        limits:
          cpus: "0.30"
          memory: "50MB"

  api1: &api
    build: .
    hostname: api1
    environment:
      - APP_PORT=8080
      - PROCESSOR_DEFAULT_URL=http://payment-processor-default:8080/payments
      - PROCESSOR_FALLBACK_URL=http://payment-processor-fallback:8080/payments
      - WORKER_CONCURRENCY=16
      - CLUSTER_NODE_ID=api1
      - CLUSTER_LISTEN=0.0.0.0:3000
      - CLUSTER_PEERS=api1@api1:3000
    networks:
      - backend
      - payment-processor
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "200MB"

  # api2:
  #   <<: *api
  #   hostname: api2
  #   environment:
  #     - APP_PORT=8080
  #     - PROCESSOR_DEFAULT_URL=http://payment-processor-default:8080/payments
  #     - PROCESSOR_FALLBACK_URL=http://payment-processor-fallback:8080/payments
  #     - WORKER_CONCURRENCY=5
  #     - CLUSTER_NODE_ID=api2
  #     - CLUSTER_LISTEN=0.0.0.0:3001
  #     - CLUSTER_PEERS=api1@api1:3000,api2@api2:3001
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: "0.40"
  #         memory: "100MB"
    
  # valkey:
  #   image: valkey/valkey:8.1.3-alpine
  #   container_name: rinha-valkey
  #   command: valkey-server --save "" --appendonly no --maxclients 20000 --io-threads 4 --io-threads-do-reads yes
  #   networks:
  #     - backend
  #   healthcheck:
  #     test: [ "CMD", "valkey-cli", "ping" ]
  #     interval: 5s
  #     timeout: 5s
  #     retries: 5
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: "0.25"
  #         memory: "100MB"
          
networks:
  backend:
    driver: bridge
  payment-processor:
    external: true
